{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778ef632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/host/d/Github')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "import SimpleITK as sitk\n",
    "import shutil\n",
    "from scipy.ndimage import binary_erosion, distance_transform_edt\n",
    "import Aorta_segmentation_ZC.functions_collection as ff\n",
    "import Aorta_segmentation_ZC.Data_processing as Data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c52675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13)\n"
     ]
    }
   ],
   "source": [
    "patient_list = pd.read_excel('/host/d/Data/CTA/Patient_lists/resampled_data_info_with_train_test_split_TAA.xlsx')\n",
    "patient_list = patient_list[patient_list['batch']=='test']\n",
    "print(patient_list.shape)\n",
    "\n",
    "save_path = '/host/d/projects/aorta_seg/models/Dataset504_AortaTAA/results/EncUNetM_3d_fullres/predicts'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba6f3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "for idx in range(patient_list.shape[0]):\n",
    "    patient_class = patient_list.iloc[idx]['class']\n",
    "    patient_subclass = str(patient_list.iloc[idx]['subclass'])\n",
    "    patient_id = patient_list.iloc[idx]['id']\n",
    "    patient_index = patient_list.iloc[idx]['patient_index']\n",
    "\n",
    "    save_folder = os.path.join(save_path,  patient_class, patient_subclass, patient_id, 'fold_'+str(fold))\n",
    "    ff.make_folder([os.path.join(save_path, patient_class),\n",
    "                    os.path.join(save_path, patient_class, patient_subclass),\n",
    "                    os.path.join(save_path, patient_class, patient_subclass, patient_id),\n",
    "                    save_folder])\n",
    "    \n",
    "    # original path filename is Aorta_XXXX where XXXX is the patient_index with leading zeros\n",
    "    original_path = os.path.join(os.path.dirname(save_path), 'predicts_raw/fold_'+str(fold), 'AortaTAA_' + str(patient_index).zfill(4) + '.nii.gz')\n",
    "    save_filename = os.path.join(save_folder,'pred_seg.nii.gz')\n",
    "\n",
    "    shutil.copyfile(original_path, save_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6504b",
   "metadata": {},
   "source": [
    "### ensemble folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f5282a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13)\n"
     ]
    }
   ],
   "source": [
    "patient_list = pd.read_excel('/host/d/Data/CTA/Patient_lists/resampled_data_info_with_train_test_split_TAA.xlsx')\n",
    "patient_list = patient_list[patient_list['batch']=='test']\n",
    "print(patient_list.shape)\n",
    "\n",
    "save_path = '/host/d/projects/aorta_seg/models/Dataset504_AortaTAA/results/EncUNetM_3d_fullres/predicts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e2d19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "def remove_scatter(mask3d: np.ndarray,\n",
    "                   target_label: int = 1,\n",
    "                   connectivity: int = 26,\n",
    "                   return_is_single: bool = False):\n",
    "    \"\"\"\n",
    "    Keep only the largest 3D connected component of voxels == target_label.\n",
    "\n",
    "    Args:\n",
    "        mask3d: 3D numpy array, e.g. (X,Y,Z) with integer labels.\n",
    "        target_label: which label to process (default 1).\n",
    "        connectivity: 6, 18, or 26 for 3D connectivity.\n",
    "        return_is_single: if True, also return whether it was a single component.\n",
    "\n",
    "    Returns:\n",
    "        cleaned_mask: same shape as mask3d, only largest component kept for target_label.\n",
    "        (optional) is_single: bool, whether original target_label voxels form exactly 1 component.\n",
    "        (optional) n_components: int, number of connected components (excluding background).\n",
    "    \"\"\"\n",
    "    assert mask3d.ndim == 3, f\"mask3d must be 3D, got {mask3d.ndim}D\"\n",
    "\n",
    "    # binary mask for the target label\n",
    "    bin_mask = (mask3d == target_label)\n",
    "\n",
    "    # if empty, return as-is\n",
    "    if not np.any(bin_mask):\n",
    "        if return_is_single:\n",
    "            return mask3d.copy(), True, 0\n",
    "        return mask3d.copy()\n",
    "\n",
    "    # choose connectivity structure\n",
    "    if connectivity == 6:\n",
    "        structure = ndimage.generate_binary_structure(3, 1)\n",
    "    elif connectivity == 18:\n",
    "        structure = ndimage.generate_binary_structure(3, 2)\n",
    "        # generate_binary_structure(3,2) actually gives 18-neighborhood in 3D\n",
    "    elif connectivity == 26:\n",
    "        structure = np.ones((3, 3, 3), dtype=bool)\n",
    "    else:\n",
    "        raise ValueError(\"connectivity must be one of {6, 18, 26}\")\n",
    "\n",
    "    labeled, ncomp = ndimage.label(bin_mask, structure=structure)\n",
    "\n",
    "    # 判断是否单一连通域\n",
    "    is_single = (ncomp == 1)\n",
    "\n",
    "    if ncomp <= 1:\n",
    "        cleaned = mask3d.copy()\n",
    "        if return_is_single:\n",
    "            return cleaned, is_single, ncomp\n",
    "        return cleaned\n",
    "\n",
    "    # compute component sizes (exclude background label 0)\n",
    "    sizes = ndimage.sum(bin_mask, labeled, index=np.arange(1, ncomp + 1))\n",
    "    largest_cc = int(np.argmax(sizes) + 1)\n",
    "\n",
    "    largest_mask = (labeled == largest_cc)\n",
    "\n",
    "    # build output: keep only largest CC for target_label, keep other labels unchanged\n",
    "    cleaned = mask3d.copy()\n",
    "    # remove all target_label first\n",
    "    cleaned[bin_mask] = 0\n",
    "    # put back the largest CC as target_label\n",
    "    cleaned[largest_mask] = target_label\n",
    "\n",
    "    if return_is_single:\n",
    "        return cleaned, is_single, ncomp\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6569760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patient: t0\n",
      "is single component before cleaning: True\n",
      "Processing patient: t1\n",
      "is single component before cleaning: True\n",
      "Processing patient: t0\n",
      "is single component before cleaning: False\n",
      "Processing patient: t1\n",
      "is single component before cleaning: True\n",
      "Processing patient: t0\n",
      "is single component before cleaning: True\n",
      "Processing patient: t1\n",
      "is single component before cleaning: True\n",
      "Processing patient: t0\n",
      "is single component before cleaning: True\n",
      "Processing patient: t1\n",
      "is single component before cleaning: True\n",
      "Processing patient: t0\n",
      "is single component before cleaning: True\n",
      "Processing patient: t1\n",
      "is single component before cleaning: True\n",
      "Processing patient: t0\n",
      "is single component before cleaning: True\n",
      "Processing patient: t1\n",
      "is single component before cleaning: True\n",
      "Processing patient: t1\n",
      "is single component before cleaning: True\n"
     ]
    }
   ],
   "source": [
    "for idx in range(patient_list.shape[0]):\n",
    "    patient_class = patient_list.iloc[idx]['class']\n",
    "    patient_subclass = str(patient_list.iloc[idx]['subclass'])\n",
    "    patient_id = patient_list.iloc[idx]['id']\n",
    "    patient_index = patient_list.iloc[idx]['patient_index']\n",
    "\n",
    "    # print('Processing patient:', patient_id)\n",
    "\n",
    "    save_folder = os.path.join(save_path,  patient_class, patient_subclass, patient_id, 'final')\n",
    "    ff.make_folder([save_folder])\n",
    "    \n",
    "    fold0_result = os.path.join(os.path.dirname(save_folder), 'fold_0/pred_seg.nii.gz')\n",
    "    affine = nb.load(fold0_result).affine\n",
    "    fold0_result = nb.load(fold0_result).get_fdata()\n",
    "\n",
    "    # fold1_result = os.path.join(os.path.dirname(save_folder), 'fold_1/pred_seg.nii.gz')\n",
    "    # fold1_result = nb.load(fold1_result).get_fdata()\n",
    "    # fold2_result = os.path.join(os.path.dirname(save_folder), 'fold_2/pred_seg.nii.gz')\n",
    "    # fold2_result = nb.load(fold2_result).get_fdata()\n",
    "\n",
    "    # stacked = np.stack([fold0_result, fold1_result, fold2_result], axis=0)\n",
    "    # final_result = (np.sum(stacked, axis=0) >= 2).astype(np.uint8)\n",
    "\n",
    "    final_result = fold0_result\n",
    "\n",
    "    # do connected component analysis to keep the largest component only\n",
    "    final_result, is_single ,_ = remove_scatter(final_result, target_label=1, connectivity=26, return_is_single=True)\n",
    "    # print('is single component before cleaning:', is_single)\n",
    "   \n",
    "\n",
    "    nb.save(nb.Nifti1Image(final_result, affine), os.path.join(save_folder, 'pred_seg.nii.gz'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1472f07",
   "metadata": {},
   "source": [
    "### resample back to original spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4261371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13)\n"
     ]
    }
   ],
   "source": [
    "patient_list = pd.read_excel('/host/d/Data/CTA/Patient_lists/resampled_data_info_with_train_test_split_TAA.xlsx')\n",
    "patient_list = patient_list[patient_list['batch']=='test']\n",
    "print(patient_list.shape)\n",
    "\n",
    "original_spacing_info = pd.read_excel('/host/d/Data/CTA/Patient_lists/original_data_info_TAA.xlsx', dtype={'subclass': str})\n",
    "\n",
    "save_path = '/host/d/projects/aorta_seg/models/Dataset504_AortaTAA/results/EncUNetM_3d_fullres/predicts'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51056913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient subclass and id: 218 t0\n",
      "original spacing: 0.822265625 0.822265625 0.800000011920929\n",
      "index i : 0  patient_subclass: 218  patient_id: t0  dimension mismatch before cropping: (250, 379, 379) (250, 380, 379)\n",
      "After cropping/padding, new shape: (250, 380, 379)\n",
      "patient subclass and id: 218 t1\n",
      "original spacing: 0.6835939884185791 0.6835939884185791 0.625\n",
      "index i : 1  patient_subclass: 218  patient_id: t1  dimension mismatch before cropping: (250, 380, 504) (250, 380, 505)\n",
      "After cropping/padding, new shape: (250, 380, 505)\n",
      "patient subclass and id: 430 t0\n",
      "original spacing: 0.76171875 0.76171875 0.800000011920929\n",
      "patient subclass and id: 430 t1\n",
      "original spacing: 0.68359375 0.68359375 0.800000011920929\n",
      "patient subclass and id: 585 t0\n",
      "original spacing: 0.73828125 0.73828125 0.800000011920929\n",
      "patient subclass and id: 585 t1\n",
      "original spacing: 0.697265625 0.697265625 0.699999988079071\n",
      "index i : 5  patient_subclass: 585  patient_id: t1  dimension mismatch before cropping: (250, 381, 431) (250, 380, 431)\n",
      "After cropping/padding, new shape: (250, 380, 431)\n",
      "patient subclass and id: 607 t0\n",
      "original spacing: 0.68359375 0.68359375 0.800000011920929\n",
      "patient subclass and id: 607 t1\n",
      "original spacing: 0.724609375 0.724609375 0.5\n",
      "index i : 7  patient_subclass: 607  patient_id: t1  dimension mismatch before cropping: (250, 381, 639) (250, 380, 639)\n",
      "After cropping/padding, new shape: (250, 380, 639)\n",
      "patient subclass and id: 881 t0\n",
      "original spacing: 0.68359375 0.68359375 0.800000011920929\n",
      "patient subclass and id: 881 t1\n",
      "original spacing: 0.6074219942092896 0.6074219942092896 0.625\n",
      "index i : 9  patient_subclass: 881  patient_id: t1  dimension mismatch before cropping: (249, 380, 463) (250, 380, 463)\n",
      "After cropping/padding, new shape: (250, 380, 463)\n",
      "patient subclass and id: 1115 t0\n",
      "original spacing: 0.703125 0.703125 0.625\n",
      "patient subclass and id: 1115 t1\n",
      "original spacing: 0.703125 0.703125 0.625\n",
      "patient subclass and id: 1116 t1\n",
      "original spacing: 0.703125 0.703125 0.625\n",
      "index i : 12  patient_subclass: 1116  patient_id: t1  dimension mismatch before cropping: (250, 380, 533) (250, 380, 532)\n",
      "After cropping/padding, new shape: (250, 380, 532)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, patient_list.shape[0]):\n",
    "    patient_class = patient_list.iloc[i]['class']\n",
    "    patient_subclass = str(patient_list.iloc[i]['subclass'])\n",
    "    patient_id = patient_list.iloc[i]['id']\n",
    "    patient_index = patient_list.iloc[i]['patient_index']\n",
    "    print('patient subclass and id:', patient_subclass, patient_id)\n",
    "\n",
    "    save_folder = os.path.join(save_path,  patient_class, patient_subclass, patient_id,'final')\n",
    "\n",
    "    pred_path = os.path.join(save_folder, 'pred_seg.nii.gz')\n",
    "\n",
    "    # find out original spacing\n",
    "    # row is confirmed by maching patient_subclass and patient_id\n",
    "    original_record = original_spacing_info[(original_spacing_info['subclass']==patient_subclass) & (original_spacing_info['id']==patient_id)]\n",
    "\n",
    "    original_spacing_x = original_record['spacing_x'].values[0]\n",
    "    original_spacing_y = original_record['spacing_y'].values[0]\n",
    "    original_spacing_z = original_record['spacing_z'].values[0]\n",
    "\n",
    "    print('original spacing:', original_spacing_x, original_spacing_y, original_spacing_z)\n",
    "\n",
    "    # do segmentation\n",
    "    seg_nifti = nb.load(pred_path)\n",
    "    seg = seg_nifti.get_fdata()\n",
    "    seg_resampled_nifti = Data_processing.resample_nifti(seg_nifti, order = 0, mode = 'nearest', cval = 0, in_plane_resolution_mm = original_spacing_x, slice_thickness_mm = original_spacing_z, number_of_slices = None)\n",
    "    header = seg_resampled_nifti.header\n",
    "    affine = seg_resampled_nifti.affine\n",
    "    seg_resampled_data = seg_resampled_nifti.get_fdata()\n",
    "    seg_resampled_data = np.round(seg_resampled_data).astype(np.int16)\n",
    "\n",
    "    # check dimensions\n",
    "    original_seg = os.path.join('/host/d/Data/CTA/original_data/', patient_class, patient_subclass, patient_id, 'seg_cropped.nii.gz')\n",
    "    original_seg_nifti = nb.load(original_seg).get_fdata()\n",
    "\n",
    "    if seg_resampled_data.shape != original_seg_nifti.shape:\n",
    "        print('index i :', i, ' patient_subclass:', patient_subclass, ' patient_id:', patient_id, ' dimension mismatch before cropping:', seg_resampled_data.shape, original_seg_nifti.shape)\n",
    "        seg_resampled_data = Data_processing.crop_or_pad(seg_resampled_data, original_seg_nifti.shape, 0)\n",
    "        seg_resample_data = Data_processing.correct_shift_caused_in_pad_crop_loop(seg_resampled_data)\n",
    "        print('After cropping/padding, new shape:', seg_resampled_data.shape)\n",
    "        assert seg_resampled_data.shape == original_seg_nifti.shape, f\"After cropping/padding, shape still mismatch: {seg_resampled_data.shape} vs {original_seg_nifti.shape}\"\n",
    "\n",
    "    seg_resampled_nifti = nb.Nifti1Image(seg_resampled_data, affine, header)\n",
    "    nb.save(seg_resampled_nifti, os.path.join(save_folder, 'pred_seg_original_res.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50f23d",
   "metadata": {},
   "source": [
    "### quantitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71bd60fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13)\n"
     ]
    }
   ],
   "source": [
    "patient_list = pd.read_excel('/host/d/Data/CTA/Patient_lists/resampled_data_info_with_train_test_split_TAA.xlsx')\n",
    "patient_list = patient_list[patient_list['batch']=='test']\n",
    "print(patient_list.shape)\n",
    "\n",
    "pred_path = '/host/d/projects/aorta_seg/models/Dataset504_AortaTAA/results/EncUNetM_3d_fullres/predicts'\n",
    "gt_path = '/host/d/Data/CTA/processed_data/'\n",
    "original_gt_path = '/host/d/Data/CTA/original_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99f9d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HD_95_numpy(pred,gt,spacing):\n",
    "    pred = pred.astype(bool)\n",
    "    gt = gt.astype(bool)\n",
    "\n",
    "    # surface voxels\n",
    "    pred_surf = pred ^ binary_erosion(pred)\n",
    "    gt_surf = gt ^ binary_erosion(gt)\n",
    "\n",
    "    dt_gt = distance_transform_edt(~gt_surf, sampling=spacing)\n",
    "    dt_pred = distance_transform_edt(~pred_surf, sampling=spacing)\n",
    "\n",
    "    d_pred_gt = dt_gt[pred_surf]\n",
    "    d_gt_pred = dt_pred[gt_surf]\n",
    "\n",
    "    hd95=max(np.percentile(d_pred_gt,95), np.percentile(d_gt_pred,95))\n",
    "\n",
    "    return hd95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d944afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel spacing: (1.5, 1.5, 1.5009902)\n",
      "for patient_class:  TAA_peking , subclass:  218 , id:  t0\n",
      "Dice score:  0.964567077254158  original_res dice:  0.9565414498401236\n",
      "HD 95:  2.1220206025104282  original_res hd:  2.294446144175214\n",
      "pixel spacing: (1.5, 1.5, 1.5029762)\n",
      "for patient_class:  TAA_peking , subclass:  218 , id:  t1\n",
      "Dice score:  0.9657858333628939  original_res dice:  0.9583421444757664\n",
      "HD 95:  2.1213203435596424  original_res hd:  1.9745895029119602\n",
      "pixel spacing: (1.5, 1.5, 1.4995672)\n",
      "for patient_class:  TAA_peking , subclass:  430 , id:  t0\n",
      "Dice score:  0.9349328964392672  original_res dice:  0.9344297383157278\n",
      "HD 95:  3.3541019662496847  original_res hd:  3.231698960891643\n",
      "pixel spacing: (1.5, 1.5, 1.4991305)\n",
      "for patient_class:  TAA_peking , subclass:  430 , id:  t1\n",
      "Dice score:  0.9653288297238249  original_res dice:  0.956474284017235\n",
      "HD 95:  2.1207055944609894  original_res hd:  2.2128041376247602\n",
      "pixel spacing: (1.5, 1.5, 1.4985366)\n",
      "for patient_class:  TAA_peking , subclass:  585 , id:  t0\n",
      "Dice score:  0.9685812604103761  original_res dice:  0.960829613324668\n",
      "HD 95:  2.5972315841801112  original_res hd:  2.51098772911437\n",
      "pixel spacing: (1.5, 1.5, 1.500995)\n",
      "for patient_class:  TAA_peking , subclass:  585 , id:  t1\n",
      "Dice score:  0.9491584699453575  original_res dice:  0.9434142192667607\n",
      "HD 95:  2.1213203435596424  original_res hd:  2.0927099172517494\n",
      "pixel spacing: (1.5, 1.5, 1.5009524)\n",
      "for patient_class:  TAA_peking , subclass:  607 , id:  t0\n",
      "Dice score:  0.951982370338873  original_res dice:  0.9410574225713407\n",
      "HD 95:  4.746127048904377  original_res hd:  4.990911975461175\n",
      "pixel spacing: (1.5, 1.5, 1.5)\n",
      "for patient_class:  TAA_peking , subclass:  607 , id:  t1\n",
      "Dice score:  0.9368058215243248  original_res dice:  0.9206554814280462\n",
      "HD 95:  9.604686356149273  original_res hd:  9.371540092343018\n",
      "pixel spacing: (1.5, 1.5, 1.5010309)\n",
      "for patient_class:  TAA_peking , subclass:  881 , id:  t0\n",
      "Dice score:  0.9279209558238969  original_res dice:  0.9248677348406054\n",
      "HD 95:  3.0  original_res hd:  3.08194800280178\n",
      "pixel spacing: (1.5, 1.5, 1.4993523)\n",
      "for patient_class:  TAA_peking , subclass:  881 , id:  t1\n",
      "Dice score:  0.9377725210514293  original_res dice:  0.9373622523708425\n",
      "HD 95:  2.998704671859741  original_res hd:  2.5044650414482197\n",
      "pixel spacing: (1.5, 1.5, 1.4994131)\n",
      "for patient_class:  TAA_peking , subclass:  1115 , id:  t0\n",
      "Dice score:  0.9569249016119501  original_res dice:  0.9503396085840862\n",
      "HD 95:  3.6732763263418615  original_res hd:  3.7312356050811104\n",
      "pixel spacing: (1.5, 1.5, 1.5012562)\n",
      "for patient_class:  TAA_peking , subclass:  1115 , id:  t1\n",
      "Dice score:  0.9711527566906137  original_res dice:  0.9629514791031949\n",
      "HD 95:  2.1213203435596424  original_res hd:  1.988737822087165\n",
      "pixel spacing: (1.5, 1.5, 1.4977478)\n",
      "for patient_class:  TAA_peking , subclass:  1116 , id:  t1\n",
      "Dice score:  0.9673493860975998  original_res dice:  0.9564134277825671\n",
      "HD 95:  2.1197283809907033  original_res hd:  2.34375\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for idx in range(patient_list.shape[0]):\n",
    "   patient_class = patient_list.iloc[idx]['class']\n",
    "   patient_subclass = str(patient_list.iloc[idx]['subclass'])\n",
    "   patient_id = patient_list.iloc[idx]['id']\n",
    "   patient_index = patient_list.iloc[idx]['patient_index']\n",
    "    \n",
    "   pred_filename = os.path.join(pred_path,  patient_class, patient_subclass, patient_id, 'fold_0', 'pred_seg.nii.gz')\n",
    "   gt_filename = os.path.join(gt_path, patient_class, patient_subclass, patient_id,'seg_resampled.nii.gz')\n",
    "\n",
    "   pred_original_res_filename = os.path.join(pred_path,  patient_class, patient_subclass, patient_id, 'final', 'pred_seg_original_res.nii.gz')\n",
    "   gt_original_res_filename = os.path.join(original_gt_path, patient_class, patient_subclass, patient_id,'seg_cropped.nii.gz')\n",
    "   # pred_final_filename = os.path.join(pred_path,  patient_class, patient_subclass, patient_id, 'final', 'pred_seg.nii.gz')\n",
    "\n",
    "   pred_seg = nb.load(pred_filename).get_fdata()\n",
    "   pred_original_res = nb.load(pred_original_res_filename).get_fdata()\n",
    "   # pred_seg_final = nb.load(pred_final_filename).get_fdata()\n",
    "\n",
    "   gt_seg = nb.load(gt_filename)\n",
    "   pixel_spacing = gt_seg.header.get_zooms()\n",
    "   print('pixel spacing:', pixel_spacing)\n",
    "   gt_seg = gt_seg.get_fdata()\n",
    "  \n",
    "   if np.unique(gt_seg).shape[0]>2:\n",
    "      gt_seg[gt_seg>0] = 1  # convert to binary mask\n",
    "\n",
    "   gt_original_res_seg = nb.load(gt_original_res_filename)\n",
    "   pixel_spacing_original_res = gt_original_res_seg.header.get_zooms()\n",
    "   gt_original_res_seg = gt_original_res_seg.get_fdata()\n",
    "   if np.unique(gt_original_res_seg).shape[0]>2:\n",
    "      gt_original_res_seg[gt_original_res_seg>0] = 1  # convert to binary mask\n",
    "\n",
    "   dice_score = ff.np_categorical_dice(pred_seg, gt_seg, target_class=1)\n",
    "   hd = HD_95_numpy(pred_seg, gt_seg, spacing=pixel_spacing)\n",
    "\n",
    "   dice_score_original_res = ff.np_categorical_dice(pred_original_res, gt_original_res_seg, target_class=1)\n",
    "   hd_original_res = HD_95_numpy(pred_original_res, gt_original_res_seg, spacing=pixel_spacing_original_res)\n",
    "\n",
    "   # dice_score_final = ff.np_categorical_dice(pred_seg_final, gt_seg, target_class=1)\n",
    "   # hd_final = HD_95_numpy(pred_seg_final, gt_seg, spacing=pixel_spacing)\n",
    "\n",
    "   print('for patient_class: ', patient_class, ', subclass: ', patient_subclass, ', id: ', patient_id)\n",
    "   print('Dice score: ', dice_score, ' original_res dice: ', dice_score_original_res)\n",
    "   print('HD 95: ', hd, ' original_res hd: ', hd_original_res)\n",
    "\n",
    "   results.append([patient_index, patient_class, patient_subclass, patient_id, dice_score, hd, dice_score_original_res, hd_original_res])\n",
    "   df = pd.DataFrame(results, columns=['patient_index', 'class', 'subclass', 'id', 'dice_1.5mm', 'hd_1.5mm','dice_original_res', 'hd_original_res'])\n",
    "   df.to_excel(os.path.join(os.path.dirname(pred_path), 'quantitative.xlsx'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb51acb",
   "metadata": {},
   "source": [
    "### result presentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3243a6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13)\n"
     ]
    }
   ],
   "source": [
    "patient_list = pd.read_excel('/host/d/Data/CTA/Patient_lists/resampled_data_info_with_train_test_split_TAA.xlsx')\n",
    "patient_list = patient_list[patient_list['batch']=='test']\n",
    "print(patient_list.shape)\n",
    "\n",
    "pred_path = '/host/d/projects/aorta_seg/models/Dataset504_AortaTAA/results/EncUNetM_3d_fullres/predicts'\n",
    "gt_original_path = '/host/d/Data/CTA/original_data/'\n",
    "gt_processed_path = '/host/d/Data/CTA/processed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f99302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for idx in range(0,patient_list.shape[0]):\n",
    "   patient_class = patient_list.iloc[idx]['class']\n",
    "   patient_subclass = str(patient_list.iloc[idx]['subclass'])\n",
    "   patient_id = patient_list.iloc[idx]['id']\n",
    "   patient_index = patient_list.iloc[idx]['patient_index']\n",
    "\n",
    "   save_folder = os.path.join(os.path.dirname(pred_path), 'examples', patient_class, patient_subclass, patient_id)\n",
    "   ff.make_folder([os.path.join(os.path.dirname(pred_path), 'examples', patient_class),\n",
    "                   os.path.join(os.path.dirname(pred_path), 'examples', patient_class, patient_subclass),\n",
    "                   os.path.join(os.path.dirname(pred_path), 'examples', patient_class, patient_subclass, patient_id),\n",
    "                   save_folder])\n",
    "\n",
    "   original_img_filename = os.path.join(gt_original_path, patient_class, patient_subclass, patient_id,'image_cropped.nii.gz')\n",
    "   original_seg_filename = os.path.join(gt_original_path, patient_class, patient_subclass, patient_id,'seg_cropped.nii.gz')\n",
    "   resampled_img_filename = os.path.join(gt_processed_path, patient_class, patient_subclass, patient_id,'img_resampled.nii.gz')\n",
    "   resampled_seg_filename = os.path.join(gt_processed_path, patient_class, patient_subclass, patient_id,'seg_resampled.nii.gz')\n",
    "\n",
    "   pred_seg_filename = os.path.join(pred_path,  patient_class, patient_subclass, patient_id, 'final', 'pred_seg.nii.gz')\n",
    "   pred_seg_original_res_filename = os.path.join(pred_path,  patient_class, patient_subclass, patient_id, 'final', 'pred_seg_original_res.nii.gz')\n",
    "\n",
    "   shutil.copyfile(original_img_filename, os.path.join(save_folder, 'image_cropped.nii.gz'))\n",
    "   shutil.copyfile(original_seg_filename, os.path.join(save_folder, 'gt_seg_cropped.nii.gz'))\n",
    "   shutil.copyfile(resampled_img_filename, os.path.join(save_folder, 'img_resampled_1.5mm.nii.gz'))\n",
    "   shutil.copyfile(resampled_seg_filename, os.path.join(save_folder, 'gt_seg_resampled_1.5mm.nii.gz'))\n",
    "   shutil.copyfile(pred_seg_original_res_filename, os.path.join(save_folder, 'pred_seg_original_res.nii.gz'))\n",
    "   shutil.copyfile(pred_seg_filename, os.path.join(save_folder, 'pred_seg_1.5mm.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0391f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.ndimage import binary_erosion, distance_transform_edt\n",
    "# pred = pred_seg.astype(bool)\n",
    "# pred_surf = pred ^ binary_erosion(pred)\n",
    "\n",
    "# # plot pred and pred_surf side by side to check\n",
    "# import matplotlib.pyplot as plt\n",
    "# slice_idx = pred.shape[2]//2\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(pred[:,:,slice_idx], cmap='gray')\n",
    "# plt.title('Predicted Segmentation')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(pred_surf[:,:,slice_idx], cmap='gray')\n",
    "# plt.title('Predicted Surface')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1675cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
